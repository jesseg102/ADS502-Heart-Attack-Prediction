---
title: "ADS 502 - Heart Attack Classification"
author: "Halee Staggs, Vicky van der Wagt, Jesse Gutierrez"
date: "2023-03-16"
output: pdf_document
---



```{r}
# Install required packages
#install.packages('tidyverse')
#install.packages('dplyr')
#install.packages('randomForest')

#load package libraries
library(ggplot2)
library(Hmisc)
library(corrplot)
library(tidyverse)
library(caret)
library(C50)
library(rpart)
library(e1071)
library(nnet)
library(NeuralNetTools)
library(data.table)
library(dplyr)
library(randomForest)

```
# The Data does not have any missing values. 

```{r}
#read in data file
data <- read_csv("heart.csv")

#examine data types and descriptives
summary(data)
describe(data)

#view dataset 
#View(data)

```






# Some variables need to be updated to factors because they are categorical/ordinal
```{r}
#update discrete/binary variables to factors
data$sex <- factor(data$sex)
data$cp <- factor(data$cp)
data$fbs <- factor(data$fbs)
data$restecg <- factor(data$restecg)
data$exng <- factor(data$exng)
data$slp <- factor(data$slp)
data$caa <- factor(data$caa)
data$output <- factor(data$output)
data$thall <- factor(data$thall)

#reexamine data summary for data types
#summary(data)
#describe(data)

head(data)
```


# Replace numerical categories with actual cateogires.
Even though they were already converted to factors, can look back on categories for reference

```{r}
#chest pain type
data$cp_cat<-c("0"="typical_angina","1"="atypical angina","3"="non-anginal pain","4"="asymptomatic")[data$cp]

#false if fasting blood sugar <=120mg/dl, otherwise true
data$fbs_cat<-c("0"="false","1"="true")[data$fbs]

#resting electrocardiographic results
data$restecg_cat<-c("0"="normal","1"="ST-T wave abnormality", "2" = "ventricular hypertrophy")[data$restecg]

#exercise induced angina
data$exng_cat<-c("0"="no","1"="yes")[data$exng]

#slope of peak exercise ST segment
data$slp_cat<-c("0"="unsloping","1"="flat", "2"="downsloaing")[data$slp]

#thalassemia
data$thall_cat<-c("0"="null","1"="fixed defect", "2"="normal", "3"="reversable defect")[data$thall]

#thalassemia
data$output_cat<-c("0"="low risk","1"="high risk")[data$output]

head(data)



```


# Examine raw distribution of each variable.
```{r}
#age is normally distributed
boxplot(data$age, main = "Distribution of Patients' Ages", ylab = 'Age')
```
```{r}
#the sample has twice as many women as men
plot(data$sex, main = "Distribution of Sex", ylab = 'Frequency', xlab = 'Sex', names = c("Male","Female"))
```

```{r}
#each type of chest pain has a different frequency
plot(data$cp, main = "Distribution of Chest Pain Types", ylab = 'Frequency', xlab = "Chest Pain Type", 
     names = c("Typical Angina", "Atypical Angina", "Non-Anginal Pain", "Asymptomatic"))
```

```{r}
#blood pressure is fairly normally distributed with a few outliers at the top end. Although they are outliers, this data is plausible and can be kept in the dataset as is
boxplot(data$trtbps, main = "Distribution of Resting Blood Pressure", ylab = 'Frequency', xlab = "Resting Blood Pressure (mmHg)")
```
```{r}
#cholesterol is normally distributed with a few outliers at the top end. These are plausible values and can be kept in the dataset
boxplot(data$chol, main = "Distribution of Cholesterol Levels", ylab = 'Cholesterol (mg/dl)')
```

```{r}
#the two groups are disproportionately represented with the majority of the sample being under 120
plot(data$fbs, main = "Fasting Blood Sugar Distribution", ylab = 'Frequency', xlab = 'Blood Sugar', 
     names = c('<= 120 mg/dl','> 120 mg/dl'))  
```     
     
```{r}
#left ventricular hypertrophy is underrepresented 
plot(data$restecg, main = "Distribtion of Resting Electrocardiographic Results", ylab = 'Frequency', xlab = 'ECG Results', 
     names = c("Normal", "ST-T Wave", "L. Vent. Hyper."))
```
```{r}
#normally distributed 
boxplot(data$thalachh, main = "Distribution of Maximum Heart Rate Achieved", ylab = 'Heart Rate (beats per minute)')
```
```{r}
plot(data$exng, main = "Distribution of Exercise-Induced Angina", xlab = 'History of Agina', ylab = 'Frequency', 
     names = c("No", "Yes"))
```

```{r}
#positively skewed
plot(data$caa, main = "Number of Major Vessels Distribution", ylab = 'Frequency', xlab = 'Number of Vessels')
```


```{r}
#the less chance group is slightly underrepresented - balance groups before running classification model
plot(data$output, main = "Distribution of Heart Attack Risk", ylab = 'Frequency', xlab = 'Chance of Heart Attack', 
     names = c("Less Chance", "More Chance"))
```


# Summary of data exploration: there are no true outliers in the data. Can leave the data as is. Some variables were not explained on the Kaggle page, so I left those ones out since I cannot interpret them. Listed below.
## data$thall
## data$oldpeak
## data$slp

# Determine if numerical variables are correlated
```{r}
#run correlation of numerical values
corrs <- cor(data[,c(1,4,5,8)])
corrplot(corrs, method = 'number', tl.cex = .9, number.cex = .9)

#variables are weakly correlated, age and maximum heart rate have strongest correlation -0.4

```

# Prepping the data for modeling

# Check for Class Imbalance
```{r}
#both classes are well represented, no need to balance 
fx_table <- table(data$output)
prop.table(fx_table)

```

## Splitting the data
```{r}
set.seed(2)
data_split <- createDataPartition(data$output, p = .7, list = FALSE, times = 1)
data_train <- data[data_split,]
data_test <- data[-data_split,]

#verify split proportions
tr_split <- round((dim(data_train)[1]/dim(data)[1])*100,1)
ts_split <- round((dim(data_test)[1]/dim(data)[1])*100,1)
tr_n <- dim(data_train)[1]
ts_n <- dim(data_test)[1]
split_train <- as.data.frame(cbind(tr_split,tr_n))
split_test <- as.data.frame(cbind(ts_split, ts_n))
split_params <- merge(split_train, split_test)
split_params
```

## Baseline Model

```{r}
baselinetable<- prop.table(table(data_train$output))
baselinetable

#baseline value assuming all predictictions as positive (1= more chance of heart disease)
accuracy_baseline = round(baselinetable[2]*100,1)


cat("baseline accuracy (all positive/'1' model): ", accuracy_baseline,"\n")
```


# Model Required - Binary Classification Model
## decision tree (need binary splits), CART5.0 (leave data as is - no binary split), KNN (all variables must be scaled - except output variable), bayesian network (convert continuous to ordinal & remove correlated variables)

# Model Testing - Decision Tree CART
```{r}
# Create the formula for the decision tree based on assigned variables
formula <- output ~ age + sex + cp + slp + fbs + thall + caa

# Build decision tree model
cart_model <- rpart(formula, data = data_train, method = "class")

# Had the adjust the dimensions of decision tree as it was too crammed
par(mar=c(5,5,2,2))
plot(cart_model, main="Classification Tree", cex=0.7, margin=0.1, branch=0.6) 
text(cart_model, use.n=TRUE, all=TRUE, cex=0.7)

# In these sets of codes, it added number of observations in each leaf
n_leaf <- table(cart_model$where)
n_leaf_pct <- paste0(sprintf("%.2f", prop.table(n_leaf)*100), "%")
n_leaf_text <- paste0(n_leaf, " (", n_leaf_pct, ")")
legend("topright", legend=n_leaf_text, bty="n", cex=0.7)

# Predict on test data
y_pred <- predict(cart_model, data_train, type = "class")

# Applied model on test data
predict_data <- predict(cart_model, data_test[-14], type = 'class')

# Created a table to determine the accuracy of the model
output <- table(data_test$output, predict_data)
output

# Calculate the accuracy of the created model
accuracy_cart <- round((sum(diag(output)) / sum(output)) * 100, 4)
print(paste('The accuracy of the model is:', paste(accuracy_cart), paste('%'), collapse = ' x '))
```

# Model Testing - Decision Tree with C5.0
```{r}
#decision tree
C5_heart <- C5.0(formula = output ~ age + sex + cp + slp + fbs + thall + caa, 
                 data = data_train) 

#Plot model
plot(C5_heart)

#test set prediction
ypred_c5 <- predict(object = C5_heart, newdata = data_test[,-14])

# confusion matrix
cont_table <- table(data_test$output, ypred_c5)
rownames(cont_table) <- c('Actual: Less', 'Actual: More')
colnames(cont_table) <- c('Pred: Less', 'Pred: More')
cont_table <- addmargins(A = cont_table, FUN = list(Total = sum), quiet = TRUE)
cont_table

#Evaluation

## Model 1: Accuracy
C5_acc <- round(((cont_table[1,1]+cont_table[2,2])/dim(data_test)[1]*100),1)

#Model 1: Error rate
C5_err <- round((100 - C5_acc),1)

#Model 1: Sensitivity
C5_sens <- round((cont_table[2,2]/(cont_table[2,1]+cont_table[2,2]))*100,1)

#Model 1: Specificity
C5_spec <- round((cont_table[1,1]/(cont_table[1,1]+cont_table[1,2]))*100,1)

#Model 1: Precision
C5_prec <- round((cont_table[2,2]/(cont_table[2,2]+cont_table[1,2]))*100,1)

#Model 1: F(1)
C5_f1 <-  round((2*((C5_prec*C5_spec)/(C5_prec+C5_spec))),1)

#combine evals into a matrix
eval_c5_table <- cbind(C5_acc, C5_err, C5_sens, C5_spec, C5_prec, C5_f1)
eval_c5_table

```
# Model Testing - Logistic Regression

```{r}
#logistic regression

#evaluate model

#test set

#evaluation

```


```{r}

# Build random forest model
rf01 <- randomForest(formula = output ~ age + sex + cp + slp + fbs + thall + caa, data = data_train, ntree = 100, type = 'classification')
# Display results
plot(rf01)

# Make predictions on the test data
rf_pred <- predict(rf01, newdata = data_test)

# Create a confusion matrix
library(caret)
confusionMatrix(rf_pred, data_test$output)

```



# Model Testing - KNN
```{r}

#first scale the data

#data_train_knn <- scale(data_train[,-14])
#data_test_knn <- scale(data_test[,-14])

#knn

#test set

#evaluation
```

# Model Testing - Bayesian Network (Naive Bayes)
```{r}
#bayesian network
library(e1071)
#generate model
nbheart <- naiveBayes(formula = output ~ age + sex + cp + slp + fbs + thall + caa, 
                 data = data_train) 

nb_ypred <- predict(object = nbheart, newdata = data_test)
#generate confusion matrix
tnb <- table(nb_ypred, data_test$output)

#extract values from confusion matrix to prep for model evaulation
TN_nb <- tnb[1,1]
FN_nb <- tnb[2,1]
FP_nb <- tnb[1,2]
TP_nb <- tnb[2,2] 

#evaluate model
decimals <-1

accuracy_nb <- round((((TP_nb+TN_nb) / (TP_nb + TN_nb + FP_nb + FN_nb)))*100,decimals)
error_rate_nb <- round((100-accuracy_nb),decimals)
sensitivity_nb <- round((TP_nb/(FN_nb+TP_nb))*100,decimals)
specificity_nb <- round((TN_nb/(TN_nb+FP_nb))*100,decimals)
precision_nb <- round((TP_nb/(TP_nb+FP_nb))*100,decimals)
recall_nb <- sensitivity_nb
f1_nb <- round((2*((precision_nb*recall_nb)/(precision_nb + recall_nb))),decimals)
f2_nb <- round((5*((precision_nb*recall_nb)/((4*precision_nb)+recall_nb))),decimals)
f3_nb <- round((1.25*((precision_nb*recall_nb)/((0.25*precision_nb)+ recall_nb))),decimals)

cat("naive bayes accuracy: ", accuracy_nb)
```
# Model Testing - Neural Network
```{r}
nn_heart <-  nnet(output ~ age + sex + cp + slp + fbs + thall + caa, data = data_train, size=20)
yprednn <- predict(nn_heart, data_test, type="class")

#visualize neural network
plotnet(nn_heart)

tnn<-table(yprednn,data_test$output)
tnn

TP_nn <- tnn[1,1]
FN_nn <- tnn[2,1]
FP_nn <- tnn[1,2]
TN_nn <- tnn[2,2] 

decimals <-1

accuracy_nn <- round((((TP_nn+TN_nn) / (TP_nn + TN_nn + FP_nn + FN_nn)))*100,decimals)
error_rate_nn <- round((100-accuracy_nn),decimals)
sensitivity_nn <- round((TP_nn/(FN_nn+TP_nn))*100,decimals)
specificity_nn <- round((TN_nn/(TN_nn+FP_nn))*100,decimals)
precision_nn <- round((TP_nn/(TP_nn+FP_nn))*100,decimals)
recall_nn <- sensitivity_nn
f1_nn <- round((2*((precision_nn*recall_nn)/(precision_nn + recall_nn))),decimals)
f2_nn <- round((5*((precision_nn*recall_nn)/((4*precision_nn)+recall_nn))),decimals)
f3_nn <- round((1.25*((precision_nn*recall_nn)/((0.25*precision_nn)+ recall_nn))),decimals)

cat("neural network accuracy: ", accuracy_nn)
```

# Model Evaulation Table

```{r }
DT = data.table(
  Model_Evaluation_Table= c("accuracy", "error rate", "sensitivity", "specificity", "precision", "F1", "F2", "F3"),
  Baseline=c(accuracy_baseline, "","","","","","",""),
  CART= c(accuracy_cart,"error rate", "sensitivity", "specificity", "precision", "F1", "F2", "F3"),
  C5.0=c(C5_acc, C5_err, C5_sens, C5_spec, C5_prec, C5_f1, "F2","F3"),
  LogisticRegression=c("accuracy", "error rate", "sensitivity", "specificity", "precision","F1", "F2", "F3"),
  KNN=c("accuracy", "error rate", "sensitivity", "specificity", "precision", "F1", "F2", "F3"),
  NaiveBayes=c(accuracy_nb, error_rate_nb, sensitivity_nb, specificity_nb, precision_nb,f1_nb, f2_nb, f3_nb),
  NeuralNetwork=c(accuracy_nn, error_rate_nn, sensitivity_nn, specificity_nn, precision_nn, f1_nn, f2_nn, f3_nn))

DT
```

# References

## Joachim Schork. (2022, May 19). Create data.table in R (3 examples): How to initialize, Construct &amp; Make. Statistics Globe. Retrieved March 26, 2023, from https://statisticsglobe.com/create-data-table-r 
## Kuhn, M. (2019). The caret package. https://topepo.github.io/caret/index.html
## Larose, C., & Larose, D. (2019). Data Science Using Python and R. John Wiley & Sons, Inc. 

